{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1aee4f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import sys\n",
    "import time\n",
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.mobile_optimizer import optimize_for_mobile\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "import models\n",
    "from models.experimental import attempt_load\n",
    "from utils.activations import Hardswish, SiLU\n",
    "from utils.general import colorstr, check_img_size, check_requirements, file_size, set_logging\n",
    "from utils.torch_utils import select_device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab659705",
   "metadata": {},
   "source": [
    "## First step load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "50a2d1bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:models.yolo:Fusing layers... \n",
      "INFO:utils.torch_utils:Model Summary: 314 layers, 7826611 parameters, 0 gradients\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda:0'\n",
    "\n",
    "model = attempt_load('./yolov7-tiny-face.pt', map_location=device)\n",
    "for k, m in model.named_modules():\n",
    "    m._non_persistent_buffers_set = set()  # pytorch 1.6.0 compatibility\n",
    "    if isinstance(m, models.common.Conv):  # assign export-friendly activations\n",
    "        if isinstance(m.act, nn.Hardswish):\n",
    "            m.act = Hardswish()\n",
    "        elif isinstance(m.act, nn.SiLU):\n",
    "            m.act = SiLU()\n",
    "    if isinstance(m, models.common.Concat):\n",
    "        m.forward = m.forward_jit\n",
    "        \n",
    "    # elif isinstance(m, models.yolo.Detect):\n",
    "    #     m.forward = m.forward_export  # assign forward (optional)\n",
    "model.model[-1].export = False\n",
    "model = model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c089b16",
   "metadata": {},
   "source": [
    "## Setting torch_tensorrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4b8625c2",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "\nExpected integer literal for index. ModuleList/Sequential indexing is only supported with integer literals. Enumeration is supported, e.g. 'for index, v in enumerate(self): ...':\n  File \"/home/pdh/torch/YOLO/yolov7-face/models/yolo.py\", line 260\n            for i in range(self.nl):\n                if self.nkpt is None or self.nkpt==0:\n                    x[i] = self.im[i](self.m[i](self.ia[i](x[i])))  # conv\n                           ~~~~~~~~~~ <--- HERE\n                else :\n                    x[i] = torch.cat((self.im[i](self.m[i](self.ia[i](x[i]))), self.m_kpt[i](x[i])), axis=1)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [6], line 13\u001b[0m\n\u001b[1;32m      2\u001b[0m enable_precisions \u001b[38;5;241m=\u001b[39m [torch\u001b[38;5;241m.\u001b[39mhalf, torch\u001b[38;5;241m.\u001b[39mfloat] \u001b[38;5;66;03m# or torch.hal\u001b[39;00m\n\u001b[1;32m      4\u001b[0m inputs \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m      5\u001b[0m     torch_tensorrt\u001b[38;5;241m.\u001b[39mInput(\n\u001b[1;32m      6\u001b[0m     min_shape \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m3\u001b[39m,\u001b[38;5;241m640\u001b[39m,\u001b[38;5;241m640\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     10\u001b[0m     )\n\u001b[1;32m     11\u001b[0m ]\n\u001b[0;32m---> 13\u001b[0m trt_ts_module \u001b[38;5;241m=\u001b[39m \u001b[43mtorch_tensorrt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menabled_precisions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43menable_precisions\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch_tensorrt/_compile.py:124\u001b[0m, in \u001b[0;36mcompile\u001b[0;34m(module, ir, inputs, enabled_precisions, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m module_type \u001b[38;5;241m==\u001b[39m _ModuleType\u001b[38;5;241m.\u001b[39mnn:\n\u001b[1;32m    120\u001b[0m         logging\u001b[38;5;241m.\u001b[39mlog(\n\u001b[1;32m    121\u001b[0m             logging\u001b[38;5;241m.\u001b[39mLevel\u001b[38;5;241m.\u001b[39mInfo,\n\u001b[1;32m    122\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModule was provided as a torch.nn.Module, trying to script the module with torch.jit.script. In the event of a failure please preconvert your module to TorchScript\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    123\u001b[0m         )\n\u001b[0;32m--> 124\u001b[0m         ts_mod \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjit\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscript\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodule\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    125\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch_tensorrt\u001b[38;5;241m.\u001b[39mts\u001b[38;5;241m.\u001b[39mcompile(\n\u001b[1;32m    126\u001b[0m         ts_mod, inputs\u001b[38;5;241m=\u001b[39minputs, enabled_precisions\u001b[38;5;241m=\u001b[39menabled_precisions, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m    127\u001b[0m     )\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m target_ir \u001b[38;5;241m==\u001b[39m _IRType\u001b[38;5;241m.\u001b[39mfx:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/jit/_script.py:1286\u001b[0m, in \u001b[0;36mscript\u001b[0;34m(obj, optimize, _frames_up, _rcb, example_inputs)\u001b[0m\n\u001b[1;32m   1284\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj, torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mModule):\n\u001b[1;32m   1285\u001b[0m     obj \u001b[38;5;241m=\u001b[39m call_prepare_scriptable_func(obj)\n\u001b[0;32m-> 1286\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjit\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_recursive\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_script_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1287\u001b[0m \u001b[43m        \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjit\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_recursive\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minfer_methods_to_compile\u001b[49m\n\u001b[1;32m   1288\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1290\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj, \u001b[38;5;28mdict\u001b[39m):\n\u001b[1;32m   1291\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m create_script_dict(obj)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/jit/_recursive.py:476\u001b[0m, in \u001b[0;36mcreate_script_module\u001b[0;34m(nn_module, stubs_fn, share_types, is_tracing)\u001b[0m\n\u001b[1;32m    474\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_tracing:\n\u001b[1;32m    475\u001b[0m     AttributeTypeIsSupportedChecker()\u001b[38;5;241m.\u001b[39mcheck(nn_module)\n\u001b[0;32m--> 476\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcreate_script_module_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnn_module\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconcrete_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstubs_fn\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/jit/_recursive.py:538\u001b[0m, in \u001b[0;36mcreate_script_module_impl\u001b[0;34m(nn_module, concrete_type, stubs_fn)\u001b[0m\n\u001b[1;32m    535\u001b[0m     script_module\u001b[38;5;241m.\u001b[39m_concrete_type \u001b[38;5;241m=\u001b[39m concrete_type\n\u001b[1;32m    537\u001b[0m \u001b[38;5;66;03m# Actually create the ScriptModule, initializing it with the function we just defined\u001b[39;00m\n\u001b[0;32m--> 538\u001b[0m script_module \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjit\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mRecursiveScriptModule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_construct\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcpp_module\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minit_fn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    540\u001b[0m \u001b[38;5;66;03m# Compile methods if necessary\u001b[39;00m\n\u001b[1;32m    541\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m concrete_type \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m concrete_type_store\u001b[38;5;241m.\u001b[39mmethods_compiled:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/jit/_script.py:615\u001b[0m, in \u001b[0;36mRecursiveScriptModule._construct\u001b[0;34m(cpp_module, init_fn)\u001b[0m\n\u001b[1;32m    602\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    603\u001b[0m \u001b[38;5;124;03mConstruct a RecursiveScriptModule that's ready for use. PyTorch\u001b[39;00m\n\u001b[1;32m    604\u001b[0m \u001b[38;5;124;03mcode should use this to construct a RecursiveScriptModule instead\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    612\u001b[0m \u001b[38;5;124;03m    init_fn:  Lambda that initializes the RecursiveScriptModule passed to it.\u001b[39;00m\n\u001b[1;32m    613\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    614\u001b[0m script_module \u001b[38;5;241m=\u001b[39m RecursiveScriptModule(cpp_module)\n\u001b[0;32m--> 615\u001b[0m \u001b[43minit_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mscript_module\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    617\u001b[0m \u001b[38;5;66;03m# Finalize the ScriptModule: replace the nn.Module state with our\u001b[39;00m\n\u001b[1;32m    618\u001b[0m \u001b[38;5;66;03m# custom implementations and flip the _initializing bit.\u001b[39;00m\n\u001b[1;32m    619\u001b[0m RecursiveScriptModule\u001b[38;5;241m.\u001b[39m_finalize_scriptmodule(script_module)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/jit/_recursive.py:516\u001b[0m, in \u001b[0;36mcreate_script_module_impl.<locals>.init_fn\u001b[0;34m(script_module)\u001b[0m\n\u001b[1;32m    513\u001b[0m     scripted \u001b[38;5;241m=\u001b[39m orig_value\n\u001b[1;32m    514\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    515\u001b[0m     \u001b[38;5;66;03m# always reuse the provided stubs_fn to infer the methods to compile\u001b[39;00m\n\u001b[0;32m--> 516\u001b[0m     scripted \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_script_module_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43morig_value\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msub_concrete_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstubs_fn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    518\u001b[0m cpp_module\u001b[38;5;241m.\u001b[39msetattr(name, scripted)\n\u001b[1;32m    519\u001b[0m script_module\u001b[38;5;241m.\u001b[39m_modules[name] \u001b[38;5;241m=\u001b[39m scripted\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/jit/_recursive.py:538\u001b[0m, in \u001b[0;36mcreate_script_module_impl\u001b[0;34m(nn_module, concrete_type, stubs_fn)\u001b[0m\n\u001b[1;32m    535\u001b[0m     script_module\u001b[38;5;241m.\u001b[39m_concrete_type \u001b[38;5;241m=\u001b[39m concrete_type\n\u001b[1;32m    537\u001b[0m \u001b[38;5;66;03m# Actually create the ScriptModule, initializing it with the function we just defined\u001b[39;00m\n\u001b[0;32m--> 538\u001b[0m script_module \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjit\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mRecursiveScriptModule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_construct\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcpp_module\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minit_fn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    540\u001b[0m \u001b[38;5;66;03m# Compile methods if necessary\u001b[39;00m\n\u001b[1;32m    541\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m concrete_type \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m concrete_type_store\u001b[38;5;241m.\u001b[39mmethods_compiled:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/jit/_script.py:615\u001b[0m, in \u001b[0;36mRecursiveScriptModule._construct\u001b[0;34m(cpp_module, init_fn)\u001b[0m\n\u001b[1;32m    602\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    603\u001b[0m \u001b[38;5;124;03mConstruct a RecursiveScriptModule that's ready for use. PyTorch\u001b[39;00m\n\u001b[1;32m    604\u001b[0m \u001b[38;5;124;03mcode should use this to construct a RecursiveScriptModule instead\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    612\u001b[0m \u001b[38;5;124;03m    init_fn:  Lambda that initializes the RecursiveScriptModule passed to it.\u001b[39;00m\n\u001b[1;32m    613\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    614\u001b[0m script_module \u001b[38;5;241m=\u001b[39m RecursiveScriptModule(cpp_module)\n\u001b[0;32m--> 615\u001b[0m \u001b[43minit_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mscript_module\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    617\u001b[0m \u001b[38;5;66;03m# Finalize the ScriptModule: replace the nn.Module state with our\u001b[39;00m\n\u001b[1;32m    618\u001b[0m \u001b[38;5;66;03m# custom implementations and flip the _initializing bit.\u001b[39;00m\n\u001b[1;32m    619\u001b[0m RecursiveScriptModule\u001b[38;5;241m.\u001b[39m_finalize_scriptmodule(script_module)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/jit/_recursive.py:516\u001b[0m, in \u001b[0;36mcreate_script_module_impl.<locals>.init_fn\u001b[0;34m(script_module)\u001b[0m\n\u001b[1;32m    513\u001b[0m     scripted \u001b[38;5;241m=\u001b[39m orig_value\n\u001b[1;32m    514\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    515\u001b[0m     \u001b[38;5;66;03m# always reuse the provided stubs_fn to infer the methods to compile\u001b[39;00m\n\u001b[0;32m--> 516\u001b[0m     scripted \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_script_module_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43morig_value\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msub_concrete_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstubs_fn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    518\u001b[0m cpp_module\u001b[38;5;241m.\u001b[39msetattr(name, scripted)\n\u001b[1;32m    519\u001b[0m script_module\u001b[38;5;241m.\u001b[39m_modules[name] \u001b[38;5;241m=\u001b[39m scripted\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/jit/_recursive.py:542\u001b[0m, in \u001b[0;36mcreate_script_module_impl\u001b[0;34m(nn_module, concrete_type, stubs_fn)\u001b[0m\n\u001b[1;32m    540\u001b[0m \u001b[38;5;66;03m# Compile methods if necessary\u001b[39;00m\n\u001b[1;32m    541\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m concrete_type \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m concrete_type_store\u001b[38;5;241m.\u001b[39mmethods_compiled:\n\u001b[0;32m--> 542\u001b[0m     \u001b[43mcreate_methods_and_properties_from_stubs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconcrete_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod_stubs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mproperty_stubs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    543\u001b[0m     \u001b[38;5;66;03m# Create hooks after methods to ensure no name collisions between hooks and methods.\u001b[39;00m\n\u001b[1;32m    544\u001b[0m     \u001b[38;5;66;03m# If done before, hooks can overshadow methods that aren't exported.\u001b[39;00m\n\u001b[1;32m    545\u001b[0m     create_hooks_from_stubs(concrete_type, hook_stubs, pre_hook_stubs)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/jit/_recursive.py:393\u001b[0m, in \u001b[0;36mcreate_methods_and_properties_from_stubs\u001b[0;34m(concrete_type, method_stubs, property_stubs)\u001b[0m\n\u001b[1;32m    390\u001b[0m property_defs \u001b[38;5;241m=\u001b[39m [p\u001b[38;5;241m.\u001b[39mdef_ \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m property_stubs]\n\u001b[1;32m    391\u001b[0m property_rcbs \u001b[38;5;241m=\u001b[39m [p\u001b[38;5;241m.\u001b[39mresolution_callback \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m property_stubs]\n\u001b[0;32m--> 393\u001b[0m \u001b[43mconcrete_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_methods_and_properties\u001b[49m\u001b[43m(\u001b[49m\u001b[43mproperty_defs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mproperty_rcbs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod_defs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod_rcbs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod_defaults\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: \nExpected integer literal for index. ModuleList/Sequential indexing is only supported with integer literals. Enumeration is supported, e.g. 'for index, v in enumerate(self): ...':\n  File \"/home/pdh/torch/YOLO/yolov7-face/models/yolo.py\", line 260\n            for i in range(self.nl):\n                if self.nkpt is None or self.nkpt==0:\n                    x[i] = self.im[i](self.m[i](self.ia[i](x[i])))  # conv\n                           ~~~~~~~~~~ <--- HERE\n                else :\n                    x[i] = torch.cat((self.im[i](self.m[i](self.ia[i](x[i]))), self.m_kpt[i](x[i])), axis=1)\n"
     ]
    }
   ],
   "source": [
    "import torch_tensorrt\n",
    "enable_precisions = [torch.half, torch.float] # or torch.hal\n",
    "\n",
    "inputs = [\n",
    "    torch_tensorrt.Input(\n",
    "    min_shape = [1,3,640,640],\n",
    "    opt_shape = [1,3,640,640],\n",
    "    max_shape = [1,3,640,640],\n",
    "    dtype= enable_precisions[0]\n",
    "    )\n",
    "]\n",
    "\n",
    "trt_ts_module = torch_tensorrt.compile(model, inputs=inputs, enabled_precisions=enable_precisions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "15421fcb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{torch.float16, torch.float32}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "150b4ceb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
